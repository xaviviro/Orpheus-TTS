# Setup Completo - Orpheus TTS Catal√°n en RunPod

## ‚úÖ Caracter√≠sticas Implementadas

### 1. Instalaci√≥n de Componentes PyTorch con Detecci√≥n CUDA

El script `setup_runpod.sh` ahora detecta autom√°ticamente la versi√≥n de CUDA instalada y usa el wheel compatible:

```bash
# Detecci√≥n autom√°tica de CUDA
CUDA_VERSION=$(python3 -c "import torch; print(torch.version.cuda)")

# Mapeo a wheel compatible:
# - CUDA 12.1 ‚Üí cu121
# - CUDA 12.4 ‚Üí cu124
# - CUDA 11.8 ‚Üí cu118
# - Otros CUDA 12.x ‚Üí cu121 (default)

# Instalaci√≥n con wheel correcto
pip install torchvision torchaudio --index-url https://download.pytorch.org/whl/${TORCH_WHEEL}
pip install torchcodec --index-url https://download.pytorch.org/whl/${TORCH_WHEEL}  # opcional
```

**Componentes instalados:**
- ‚úÖ `torchvision` - Para procesamiento de im√°genes/video
- ‚úÖ `torchaudio` - Para procesamiento de audio
- ‚úÖ `torchcodec` - Codecs adicionales (opcional, con fallback si no disponible)

**NO reinstala PyTorch** - RunPod ya lo tiene instalado.

### 2. Configuraci√≥n de Caches en /workspace

Todos los caches se guardan en `/workspace` para persistencia:

```bash
# HuggingFace
export HF_HOME=/workspace/hf_cache
export HF_DATASETS_CACHE=/workspace/hf_cache/datasets
export TRANSFORMERS_CACHE=/workspace/hf_cache/transformers
export HF_HUB_CACHE=/workspace/hf_cache/hub

# WandB
export WANDB_DIR=/workspace/wandb_cache
export WANDB_CACHE_DIR=/workspace/wandb_cache
export WANDB_PROJECT=orpheus-catalan-tts
```

### 3. Autenticaci√≥n Autom√°tica

**HuggingFace:**
```bash
# Primera vez: pide token
huggingface-cli login

# Si ya existe token: pregunta si quieres reautenticar
¬øQuieres reautenticarte? (y/N):
```

**WandB:**
```bash
# Si no est√° configurado: pregunta si quieres usarlo
¬øQuieres configurar WandB para logging? (Y/n):

# Si ya est√° configurado: pregunta si quieres reautenticar
¬øQuieres reautenticarte en WandB? (y/N):
```

### 4. Estructura de Directorios

Creada autom√°ticamente en `/workspace`:

```
/workspace/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/          # Datasets sin procesar
‚îÇ   ‚îú‚îÄ‚îÄ processed/    # Datasets procesados
‚îÇ   ‚îî‚îÄ‚îÄ tokenized/    # Datasets tokenizados
‚îú‚îÄ‚îÄ checkpoints/      # Checkpoints del modelo
‚îú‚îÄ‚îÄ logs/             # Logs de entrenamiento
‚îú‚îÄ‚îÄ outputs/          # Outputs finales
‚îú‚îÄ‚îÄ analysis/         # An√°lisis de datasets
‚îú‚îÄ‚îÄ hf_cache/         # Cache HuggingFace (persistente)
‚îî‚îÄ‚îÄ wandb_cache/      # Cache WandB (persistente)
```

## üöÄ Uso en RunPod

### Paso 1: Subir archivos

Sube la carpeta completa `finetune_catalan/` a tu pod de RunPod.

### Paso 2: Ejecutar setup

```bash
cd /workspace/Orpheus-TTS
chmod +x finetune_catalan/setup_runpod.sh
./finetune_catalan/setup_runpod.sh
```

El script:
1. ‚úÖ Verifica Python 3.10+
2. ‚úÖ Actualiza pip
3. ‚úÖ Detecta PyTorch y CUDA instalados
4. ‚úÖ Instala torchvision, torchaudio, torchcodec con wheel compatible
5. ‚úÖ Instala dependencias de Orpheus TTS
6. ‚úÖ Instala orpheus-speech y vllm
7. ‚úÖ Instala SNAC para tokenizaci√≥n
8. ‚úÖ Instala Flash Attention 2 (si es posible)
9. ‚úÖ Instala dependencias para fine-tuning
10. ‚úÖ Configura autenticaci√≥n HuggingFace
11. ‚úÖ Configura autenticaci√≥n WandB
12. ‚úÖ Crea estructura de directorios
13. ‚úÖ Configura variables de entorno permanentes
14. ‚úÖ Ejecuta validaci√≥n completa

### Paso 3: Cargar variables de entorno

```bash
source /workspace/.env
```

O agrega al `~/.bashrc` para que se cargue autom√°ticamente:

```bash
echo "source /workspace/.env" >> ~/.bashrc
```

### Paso 4: Validar setup

```bash
cd finetune_catalan
python scripts/validate_setup.py
```

Esto verifica:
- ‚úÖ Tokenizer con vocabulario extendido (>128k tokens)
- ‚úÖ Dependencias instaladas correctamente
- ‚úÖ GPU y VRAM disponibles
- ‚úÖ Caches configurados

## üìä Workflow Completo

Una vez completado el setup:

### 1. Analizar tus datasets

```bash
python scripts/analyze_speaker_distribution.py \
  --datasets xaviviro/cv_23_ca_central xaviviro/cv_23_ca_balear \
  --output /workspace/analysis/speaker_distribution.json
```

### 2. Preparar datos por dialecto

```bash
python scripts/prepare_by_dialect.py \
  --datasets xaviviro/cv_23_ca_central xaviviro/cv_23_ca_balear xaviviro/cv_23_ca_valencia \
  --output_dir /workspace/data/processed \
  --balance_speakers \
  --max_samples_per_speaker 50
```

### 3. Tokenizar datos

```bash
python scripts/tokenize_dataset.py \
  --input_dir /workspace/data/processed \
  --output_dir /workspace/data/tokenized \
  --model_name canopylabs/orpheus-tts-0.1-pretrained
```

### 4. Entrenar

```bash
python scripts/train_catalan.py \
  --config configs/config_catalan.yaml \
  --data_dir /workspace/data/tokenized \
  --output_dir /workspace/checkpoints/catalan_dialectal
```

### 5. Generar audio (inferencia)

```bash
python scripts/inference_with_orpheus_package.py \
  --model_path /workspace/checkpoints/catalan_dialectal/final_model \
  --text "Bon dia! Com est√†s avui?" \
  --dialect central \
  --output /workspace/outputs/test_central.wav
```

## üîß Caracter√≠sticas T√©cnicas

### Detecci√≥n CUDA Inteligente

El script detecta la versi√≥n exacta de CUDA:

```bash
# Verifica PyTorch instalado
if python3 -c "import torch" 2>/dev/null; then
    CUDA_VERSION=$(python3 -c "import torch; print(torch.version.cuda)")

    # Mapea a wheel compatible
    if [[ "$CUDA_VERSION" == "12.1"* ]]; then
        TORCH_WHEEL="cu121"
    elif [[ "$CUDA_VERSION" == "12.4"* ]]; then
        TORCH_WHEEL="cu124"
    # ... etc
fi
```

### Manejo de Errores

- **torchcodec no disponible**: Marca como opcional, contin√∫a sin error
- **Flash Attention falla**: Marca como opcional, contin√∫a sin error
- **Sin GPU**: Advierte pero permite continuar (CPU mode)
- **PyTorch no instalado**: Instala versi√≥n completa autom√°ticamente

### Variables de Entorno Persistentes

El archivo `/workspace/.env` contiene:

```bash
# Directorios de trabajo
export WORK_DIR=/workspace/orpheus-catalan
export DATA_DIR=/workspace/data
export CHECKPOINT_DIR=/workspace/checkpoints
export LOG_DIR=/workspace/logs
export OUTPUT_DIR=/workspace/outputs

# PyTorch optimizaciones
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# HuggingFace - TODOS en /workspace
export HF_HOME=/workspace/hf_cache
export HF_DATASETS_CACHE=/workspace/hf_cache/datasets
export TRANSFORMERS_CACHE=/workspace/hf_cache/transformers

# WandB
export WANDB_DIR=/workspace/wandb_cache
export WANDB_CACHE_DIR=/workspace/wandb_cache
export WANDB_PROJECT=orpheus-catalan-tts

# Optimizaciones
export OMP_NUM_THREADS=8
export TOKENIZERS_PARALLELISM=true
```

## üéØ Estrategia para tus Datasets

Como tus datasets tienen **muchos hablantes con pocos audios cada uno**, la estrategia recomendada es:

### Fase 1: Pretraining Dialectal (ahora)

Entrenar un modelo por dialecto usando TODOS los hablantes:

```bash
# Central: 300+ hablantes ‚Üí modelo aprende catal√°n central
# Balear: 200+ hablantes ‚Üí modelo aprende balear
# Valenci√†: 300+ hablantes ‚Üí modelo aprende valenci√†
```

**Ventajas:**
- ‚úÖ Usas TODOS tus datos
- ‚úÖ El modelo aprende caracter√≠sticas fon√©ticas del dialecto
- ‚úÖ No necesitas 300+ muestras por hablante individual

### Fase 2: Voice Cloning (despu√©s, opcional)

Para voces espec√≠ficas de producci√≥n:

```bash
# Seleccionar 2-3 voces con mejor calidad
# Usar voice cloning con 3-10 segundos de referencia
```

**Ver m√°s detalles en:**
- [ESTRATEGIA_RECOMENDADA.md](ESTRATEGIA_RECOMENDADA.md)
- [EJEMPLO_TUS_DATASETS.md](EJEMPLO_TUS_DATASETS.md)

## üìö Documentaci√≥n Completa

- **[INDEX.md](INDEX.md)** - √çndice de toda la documentaci√≥n
- **[QUICKSTART.md](QUICKSTART.md)** - Gu√≠a r√°pida (10 minutos)
- **[README.md](README.md)** - Documentaci√≥n completa
- **[MEJORES_PRACTICAS_OFICIAL.md](MEJORES_PRACTICAS_OFICIAL.md)** - Gu√≠a oficial de Canopy Labs
- **[TOKENIZATION_GUIDE.md](TOKENIZATION_GUIDE.md)** - C√≥mo funciona SNAC

## ‚úÖ Checklist Pre-Entrenamiento

Antes de empezar a entrenar, verifica:

- [ ] Setup completado: `./setup_runpod.sh`
- [ ] Variables de entorno cargadas: `source /workspace/.env`
- [ ] Validaci√≥n exitosa: `python scripts/validate_setup.py`
- [ ] HuggingFace autenticado: `huggingface-cli whoami`
- [ ] WandB autenticado: `wandb status` (opcional)
- [ ] GPU disponible: `nvidia-smi`
- [ ] Datasets analizados: `python scripts/analyze_speaker_distribution.py`
- [ ] Configuraci√≥n revisada: `configs/config_catalan.yaml`

## üÜò Resoluci√≥n de Problemas

### Error: "Token fuera de rango"
**Causa**: Tokenizer sin vocabulario extendido de SNAC
**Soluci√≥n**: Usar `canopylabs/orpheus-tts-0.1-pretrained` como modelo base

### Error: "CUDA out of memory"
**Causa**: Secuencias muy largas o batch_size alto
**Soluci√≥n**:
- Reducir `batch_size` en config
- Filtrar audios >15s en preparaci√≥n de datos
- Activar `gradient_checkpointing`

### Error: "torchcodec no disponible"
**Causa**: No hay wheel para tu versi√≥n de CUDA
**Soluci√≥n**: Es opcional, el script contin√∫a sin error

### Error: "Flash Attention failed"
**Causa**: Compilaci√≥n requiere CUDA toolkit
**Soluci√≥n**: Es opcional, entrenar√°s sin Flash Attention (m√°s lento pero funciona)

### Error: "std::bad_alloc" durante an√°lisis de datasets
**Causa**: Dataset muy grande (1M+ muestras) consume toda la RAM
**Soluci√≥n**: El script `analyze_speaker_distribution.py` ahora usa streaming mode autom√°ticamente. Simplemente vuelve a ejecutar el script - procesar√° en modo streaming sin cargar todo en memoria.

## üéâ ¬°Listo!

Ahora tienes un entorno completo para entrenar Orpheus TTS en catal√°n con variantes dialectales.

**Siguiente paso**: Ejecuta el setup y sigue el [QUICKSTART.md](QUICKSTART.md)

---

**Versi√≥n**: 1.0
**Fecha**: 2025-11-07
**Compatible con**: RunPod, CUDA 11.8+, PyTorch 2.0+
