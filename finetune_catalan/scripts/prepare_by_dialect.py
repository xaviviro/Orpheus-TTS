"""
Script para preparar datasets agrupando por VARIANTE DIALECTAL (no por hablante).

Estrategia: Entrenar voces representativas de cada dialecto, luego usar
voice cloning para adaptar a hablantes especÃ­ficos.

Esta estrategia es ideal cuando tienes muchos hablantes con pocos audios cada uno.

NOTA: Este script NO procesa/resamplea audio - lo deja tal cual estÃ¡ en el dataset original.
Solo formatea el texto y organiza los datos por dialecto.
"""

import argparse
from datasets import load_dataset, DatasetDict, concatenate_datasets
from pathlib import Path
from tqdm import tqdm
import json
from collections import defaultdict, Counter


# Mapeo de variantes a nombres de voz "genÃ©ricos" por dialecto
DIALECT_VOICE_NAMES = {
    'central': 'central',           # Dialecto central
    'balearic': 'balear',           # Dialecto balear
    'valencian': 'valencia',        # Dialecto valenciano
    'alacanti': 'alacanti',         # AlacantÃ­
    'tortosi': 'tortosi',           # TortosÃ­
    'septentrional': 'septentrional',  # Septentrional
    'northwestern': 'occidental',   # Nord-occidental
}


def parse_args():
    parser = argparse.ArgumentParser(
        description='Preparar datasets por variante dialectal (estrategia voice cloning)'
    )
    parser.add_argument(
        '--datasets',
        type=str,
        nargs='+',
        required=True,
        help='Lista de datasets a procesar'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default='../data/processed_by_dialect',
        help='Directorio de salida'
    )
    parser.add_argument(
        '--min_duration',
        type=float,
        default=1.0,
        help='DuraciÃ³n mÃ­nima del audio'
    )
    parser.add_argument(
        '--max_duration',
        type=float,
        default=20.0,
        help='DuraciÃ³n mÃ¡xima del audio'
    )
    parser.add_argument(
        '--samples_per_dialect',
        type=int,
        default=None,
        help='NÃºmero mÃ¡ximo de muestras por dialecto (None para todas)'
    )
    parser.add_argument(
        '--min_samples_per_speaker',
        type=int,
        default=3,
        help='MÃ­nimo de muestras por hablante para incluirlo'
    )
    parser.add_argument(
        '--balance_speakers',
        action='store_true',
        help='Balancear muestras entre hablantes del mismo dialecto'
    )
    parser.add_argument(
        '--max_samples_per_speaker',
        type=int,
        default=50,
        help='MÃ¡ximo de muestras por hablante (para balancear)'
    )
    parser.add_argument(
        '--save_speaker_metadata',
        action='store_true',
        help='Guardar metadata de hablantes para posterior voice cloning'
    )
    parser.add_argument(
        '--num_workers',
        type=int,
        default=None,
        help='NÃºmero de workers para filtrado con multiprocessing'
    )
    parser.add_argument(
        '--hf_repo',
        type=str,
        default=None,
        help='Repositorio de HuggingFace para subir cada dialecto (ej: xaviviro/cv_23_ca_distilled)'
    )
    return parser.parse_args()


def get_variant_from_dataset_name(dataset_name):
    """Extrae la variante del nombre del dataset."""
    dataset_lower = dataset_name.lower()

    # Mapeo de patrones a variantes
    if 'central' in dataset_lower:
        return 'central'
    elif 'balear' in dataset_lower:
        return 'balearic'
    elif 'valencia' in dataset_lower and 'nord_occidental' not in dataset_lower:
        return 'valencian'
    elif 'alacant' in dataset_lower:
        return 'alacanti'
    elif 'tortosi' in dataset_lower:
        return 'tortosi'
    elif 'septentrional' in dataset_lower:
        return 'septentrional'
    elif 'nord_occidental' in dataset_lower or 'northwestern' in dataset_lower:
        return 'northwestern'

    return 'unknown'


def filter_by_duration(example, min_dur, max_dur):
    """Filtra por duraciÃ³n."""
    if 'audio' not in example or example['audio'] is None:
        return False
    audio_array = example['audio']['array']
    sample_rate = example['audio']['sampling_rate']
    duration = len(audio_array) / sample_rate
    return min_dur <= duration <= max_dur




def balance_by_speakers(dataset, max_per_speaker):
    """
    Balancea el dataset limitando muestras por hablante.

    Esto evita que hablantes con muchos audios dominen el entrenamiento.
    """
    speaker_samples = defaultdict(list)

    # Agrupar por hablante
    for i, example in enumerate(tqdm(dataset, desc="ğŸ“Š Agrupando por hablante")):
        speaker_id = example.get('client_id', 'unknown')
        speaker_samples[speaker_id].append(i)

    # Seleccionar hasta max_per_speaker de cada hablante
    selected_indices = []
    for speaker, indices in tqdm(speaker_samples.items(), desc="âš–ï¸  Balanceando hablantes"):
        if len(indices) <= max_per_speaker:
            selected_indices.extend(indices)
        else:
            # Tomar muestra aleatoria
            import random
            random.seed(42)
            selected_indices.extend(random.sample(indices, max_per_speaker))

    return dataset.select(sorted(selected_indices))


def load_and_process_dataset(dataset_name, args):
    """Carga y procesa un dataset por dialecto usando mÃ©todos nativos de datasets."""
    print(f"\n{'='*70}")
    print(f"Procesando: {dataset_name}")
    print(f"{'='*70}")

    # Detectar dialecto
    dialect = get_variant_from_dataset_name(dataset_name)
    print(f"Dialecto detectado: {dialect}")

    # Cargar dataset
    print("\nğŸ“¥ Cargando dataset desde HuggingFace Hub...")
    try:
        dataset = load_dataset(dataset_name, split='train')
        print("âœ“ Dataset cargado exitosamente")
    except Exception as e:
        print(f"âŒ Error cargando dataset: {e}")
        return None, None

    print(f"ğŸ“Š Muestras iniciales: {len(dataset):,}")

    # Determinar nÃºmero de workers para filtrado
    num_proc = args.num_workers if args.num_workers else None

    # Filtrar por duraciÃ³n
    print(f"\nğŸ” Filtrando por duraciÃ³n ({args.min_duration}s - {args.max_duration}s)...")
    if num_proc:
        print(f"  Usando {num_proc} procesos")
    original_len = len(dataset)
    dataset = dataset.filter(
        lambda x: filter_by_duration(x, args.min_duration, args.max_duration),
        num_proc=num_proc,
        desc="Filtrando por duraciÃ³n"
    )
    filtered_len = len(dataset)
    print(f"âœ“ Filtrado completado: {filtered_len}/{original_len} muestras ({filtered_len/original_len*100:.1f}% conservadas)")

    # Analizar hablantes
    print("\nğŸ” Analizando hablantes...")
    speaker_counts = Counter(
        ex.get('client_id', 'unknown')
        for ex in tqdm(dataset, desc="Contando hablantes")
    )

    # Filtrar hablantes con muy pocas muestras
    valid_speakers = {
        speaker for speaker, count in speaker_counts.items()
        if count >= args.min_samples_per_speaker
    }

    print(f"Hablantes totales: {len(speaker_counts)}")
    print(f"Hablantes con >={args.min_samples_per_speaker} muestras: {len(valid_speakers)}")

    print("\nğŸ” Filtrando por hablantes vÃ¡lidos...")
    if num_proc:
        print(f"  Usando {num_proc} procesos")
    original_filtered = len(dataset)
    dataset = dataset.filter(
        lambda x: x.get('client_id', 'unknown') in valid_speakers,
        num_proc=num_proc,
        desc="Filtrando hablantes"
    )
    after_speaker_filter = len(dataset)
    print(f"âœ“ Muestras despuÃ©s de filtrar hablantes: {after_speaker_filter}/{original_filtered} ({after_speaker_filter/original_filtered*100:.1f}% conservadas)")

    # Balancear por hablantes si se solicita
    if args.balance_speakers:
        print(f"\nâš–ï¸  Balanceando (max {args.max_samples_per_speaker} por hablante)...")
        before_balance = len(dataset)
        dataset = balance_by_speakers(dataset, args.max_samples_per_speaker)
        after_balance = len(dataset)
        print(f"âœ“ Muestras despuÃ©s de balancear: {after_balance}/{before_balance} ({after_balance/before_balance*100:.1f}% conservadas)")

    # Limitar nÃºmero total si se especifica
    if args.samples_per_dialect and len(dataset) > args.samples_per_dialect:
        print(f"\nğŸ” Limitando a {args.samples_per_dialect} muestras...")
        dataset = dataset.shuffle(seed=42).select(range(args.samples_per_dialect))
        print(f"âœ“ Limitado a {len(dataset)} muestras")

    # Renombrar columna 'sentence' a 'text' usando map
    print("\nğŸ”„ Renombrando columna 'sentence' a 'text'...")
    dataset = dataset.rename_column('sentence', 'text')
    print("âœ“ Columna renombrada")

    # AÃ±adir columna 'duration' calculada desde el audio
    print("\nğŸ”„ Calculando duraciÃ³n de audios...")
    def add_duration(example):
        example['duration'] = len(example['audio']['array']) / example['audio']['sampling_rate']
        return example

    dataset = dataset.map(
        add_duration,
        num_proc=num_proc,
        desc="Calculando duraciÃ³n"
    )
    print("âœ“ DuraciÃ³n calculada")

    # Eliminar todas las columnas excepto las que necesitamos
    print("\nğŸ—‘ï¸  Eliminando columnas innecesarias...")
    columns_to_keep = ['audio', 'text', 'duration', 'client_id']
    columns_to_remove = [col for col in dataset.column_names if col not in columns_to_keep]

    if columns_to_remove:
        print(f"  Eliminando: {', '.join(columns_to_remove)}")
        dataset = dataset.remove_columns(columns_to_remove)

    # Renombrar client_id a speaker_id
    if 'client_id' in dataset.column_names:
        dataset = dataset.rename_column('client_id', 'speaker_id')

    print(f"âœ“ Columnas finales: {', '.join(dataset.column_names)}")

    # Guardar metadata de hablantes (solo si se solicita)
    speaker_metadata = None
    if args.save_speaker_metadata:
        print("\nğŸ“‹ Guardando metadata de hablantes...")
        speaker_metadata = {}

        for example in tqdm(dataset, desc="ğŸ“ Extrayendo metadata"):
            speaker_id = example.get('speaker_id', 'unknown')
            if speaker_id not in speaker_metadata:
                speaker_metadata[speaker_id] = {
                    'dialect': dialect,
                    'samples': 0
                }
            speaker_metadata[speaker_id]['samples'] += 1

        print(f"âœ“ Metadata guardada para {len(speaker_metadata)} hablantes")

    print(f"\nâœ… Dataset procesado: {len(dataset):,} ejemplos")

    return dataset, speaker_metadata


def main():
    args = parse_args()

    print("="*70)
    print("PREPARACIÃ“N POR DIALECTO (Estrategia Voice Cloning)")
    print("="*70)
    print("\nEstrategia:")
    print("1. Entrenar voces por DIALECTO (no por hablante)")
    print("2. Usar todos los hablantes para cada dialecto")
    print("3. DespuÃ©s: Voice cloning para voces especÃ­ficas")
    print("="*70)

    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    all_datasets = []
    all_speaker_metadata = {}
    dialect_stats = {}

    # Procesar cada dataset
    print(f"\nğŸ”„ Procesando {len(args.datasets)} dataset(s)...")
    for idx, dataset_name in enumerate(args.datasets, 1):
        print(f"\n{'='*70}")
        print(f"ğŸ“¦ Dataset {idx}/{len(args.datasets)}: {dataset_name}")
        print(f"{'='*70}")

        processed_ds, speaker_meta = load_and_process_dataset(dataset_name, args)

        if processed_ds is not None:
            all_datasets.append(processed_ds)

            dialect = get_variant_from_dataset_name(dataset_name)

            # Guardar cada dialecto por separado
            dialect_dir = output_dir / dialect
            print(f"\nğŸ’¾ Guardando dialecto '{dialect}' en: {dialect_dir}")
            processed_ds.save_to_disk(str(dialect_dir))
            print("âœ“ Dialecto guardado localmente")

            # Subir a HuggingFace si se especificÃ³ repo
            if args.hf_repo:
                try:
                    print(f"\nâ˜ï¸  Subiendo '{dialect}' a HuggingFace Hub...")
                    print(f"   Repo: {args.hf_repo}")
                    print(f"   Config: {dialect}")
                    processed_ds.push_to_hub(
                        args.hf_repo,
                        config_name=dialect,
                        commit_message=f"Add {dialect} dialect (max {args.max_samples_per_speaker} samples/speaker)"
                    )
                    print(f"âœ… Dialecto '{dialect}' subido exitosamente")
                    print(f"   URL: https://huggingface.co/datasets/{args.hf_repo}/tree/main/{dialect}")
                except Exception as e:
                    print(f"âš ï¸  Error subiendo '{dialect}' a HuggingFace: {e}")
                    print("   Continuando con el siguiente dialecto...")

            # Guardar estadÃ­sticas bÃ¡sicas (sin iterar sobre el dataset)
            dialect_stats[dialect] = {
                'samples': len(processed_ds),
            }

            if speaker_meta:
                all_speaker_metadata[dialect] = speaker_meta

    if not all_datasets:
        print("\nâŒ No se pudo procesar ningÃºn dataset")
        return

    # Combinar datasets
    print("\n" + "="*70)
    print("ğŸ”— COMBINANDO DIALECTOS")
    print("="*70)

    print(f"\nğŸ“¦ Concatenando {len(all_datasets)} datasets...")
    combined_dataset = concatenate_datasets(all_datasets)
    print(f"âœ“ Total combinado: {len(combined_dataset):,} muestras")

    # Mezclar
    print("\nğŸ”€ Mezclando dataset...")
    combined_dataset = combined_dataset.shuffle(seed=42)
    print("âœ“ Dataset mezclado")

    # Dividir train/validation
    print("\nâœ‚ï¸  Dividiendo train/validation (90/10)...")
    split = combined_dataset.train_test_split(test_size=0.1, seed=42)
    print(f"âœ“ Train: {len(split['train']):,} muestras")
    print(f"âœ“ Validation: {len(split['test']):,} muestras")

    dataset_dict = DatasetDict({
        'train': split['train'],
        'validation': split['test']
    })

    # Guardar
    print(f"\nğŸ’¾ Guardando dataset en: {output_dir}")
    dataset_dict.save_to_disk(str(output_dir))
    print("âœ“ Dataset guardado en disco")

    # Guardar metadata de hablantes
    if all_speaker_metadata:
        print("\nğŸ“ Guardando metadata de hablantes...")
        metadata_path = output_dir / 'speaker_metadata.json'
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(all_speaker_metadata, f, indent=2, ensure_ascii=False)
        print(f"âœ“ Metadata guardada: {metadata_path}")

    # Guardar estadÃ­sticas
    print("\nğŸ“Š Guardando estadÃ­sticas...")
    stats_path = output_dir / 'dialect_statistics.json'
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump(dialect_stats, f, indent=2, ensure_ascii=False)
    print(f"âœ“ EstadÃ­sticas guardadas: {stats_path}")

    # Reporte final
    print("\n" + "="*70)
    print("ğŸ“Š ESTADÃSTICAS FINALES")
    print("="*70)
    print("\nğŸ“š Dataset completo:")
    print(f"  â€¢ Train: {len(dataset_dict['train']):,} muestras")
    print(f"  â€¢ Validation: {len(dataset_dict['validation']):,} muestras")
    print(f"  â€¢ Total: {len(dataset_dict['train']) + len(dataset_dict['validation']):,} muestras")

    print("\nğŸ—£ï¸  Por dialecto:")
    total_samples = 0
    for dialect, stats in sorted(dialect_stats.items()):
        voice_name = DIALECT_VOICE_NAMES.get(dialect, dialect)
        print(f"  ğŸ“ {dialect.upper()} (voz: '{voice_name}'): {stats['samples']:,} muestras")
        total_samples += stats['samples']

    print(f"\n  ğŸ¯ TOTAL: {len(dialect_stats)} dialectos, {total_samples:,} muestras")

    print("\n" + "="*70)
    print("âœ… PREPARACIÃ“N COMPLETADA CON Ã‰XITO")
    print("="*70)
    print("\nPrÃ³ximos pasos:")
    print("1. Tokenizar dataset:")
    print(f"   python scripts/tokenize_dataset.py --input_dir {output_dir} --output_dir {output_dir}_tokenized")
    print("\n2. Entrenar modelo:")
    print("   accelerate launch scripts/train_catalan.py --config configs/config_catalan.yaml")
    print("\n3. DespuÃ©s del entrenamiento, usar voice cloning:")
    print("   Ver: notebooks/voice_cloning_inference.ipynb")


if __name__ == '__main__':
    main()
