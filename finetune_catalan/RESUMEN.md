# Resumen del Proyecto: Fine-tuning Orpheus TTS para CatalÃ¡n

## Â¿QuÃ© se ha creado?

Se ha montado una estructura completa para hacer fine-tuning de Orpheus TTS al catalÃ¡n con soporte para variantes dialectales usando tus datasets de Common Voice.

## Estructura del Proyecto

```
finetune_catalan/
â”‚
â”œâ”€â”€ ğŸ“„ QUICKSTART.md              â† GuÃ­a de inicio rÃ¡pido (EMPIEZA AQUÃ)
â”œâ”€â”€ ğŸ“„ README.md                  â† DocumentaciÃ³n completa del proyecto
â”œâ”€â”€ ğŸ“„ USAGE_CUSTOM_DATASETS.md   â† GuÃ­a especÃ­fica para tus datasets
â”œâ”€â”€ ğŸ“„ TOKENIZATION_GUIDE.md      â† ExplicaciÃ³n tÃ©cnica de cÃ³mo funciona la tokenizaciÃ³n
â”œâ”€â”€ ğŸ“„ requirements.txt           â† Dependencias de Python
â”œâ”€â”€ ğŸ“„ .gitignore                 â† Archivos a ignorar en git
â”‚
â”œâ”€â”€ ğŸ”§ setup_runpod.sh           â† Script de setup automÃ¡tico para RunPod
â”‚
â”œâ”€â”€ ğŸ“ configs/
â”‚   â””â”€â”€ config_catalan.yaml      â† ConfiguraciÃ³n de entrenamiento
â”‚
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â”œâ”€â”€ prepare_custom_catalan.py          â† Para tus datasets (xaviviro/cv_23_ca_*)
â”‚   â”œâ”€â”€ prepare_commonvoice_catalan.py     â† Para datasets de projecte-aina
â”‚   â”œâ”€â”€ tokenize_dataset.py                â† TokenizaciÃ³n de audio y texto
â”‚   â””â”€â”€ train_catalan.py                   â† Script de entrenamiento
â”‚
â””â”€â”€ ğŸ“ data/                     â† Se crea automÃ¡ticamente
    â”œâ”€â”€ raw/                    â† Datasets sin procesar
    â”œâ”€â”€ processed/              â† Datasets procesados
    â””â”€â”€ tokenized/              â† Datasets tokenizados
```

## Archivos Clave

### 1. Scripts de PreparaciÃ³n

#### `scripts/prepare_custom_catalan.py`
Script principal para tus datasets. Hace:
- âœ“ Carga mÃºltiples variantes dialectales de tus datasets
- âœ“ Filtra por duraciÃ³n (min/max)
- âœ“ Filtra por calidad, gÃ©nero, edad
- âœ“ Resamplea audio de 48kHz a 24kHz
- âœ“ Asigna voces por dialecto (pau, maria, carla, etc.)
- âœ“ Formatea texto al estilo Orpheus: `{voz}: {texto}`
- âœ“ Balancea dataset por variantes
- âœ“ Divide en train/validation

**Uso**:
```bash
python scripts/prepare_custom_catalan.py \
    --datasets xaviviro/cv_23_ca_central xaviviro/cv_23_ca_balearic \
    --output_dir ./data/processed \
    --samples_per_variant 500
```

#### `scripts/tokenize_dataset.py`
Tokeniza audio usando SNAC y texto usando el tokenizer de Orpheus:
- âœ“ Tokeniza texto con vocabulario de Llama
- âœ“ Tokeniza audio con SNAC en 3 niveles jerÃ¡rquicos
- âœ“ Combina tokens de texto + audio en secuencia unificada
- âœ“ Crea formato para causal language modeling

**Uso**:
```bash
python scripts/tokenize_dataset.py \
    --input_dir ./data/processed \
    --output_dir ./data/tokenized \
    --device cuda
```

#### `scripts/train_catalan.py`
Script de entrenamiento con Transformers Trainer:
- âœ“ Carga modelo preentrenado de Orpheus
- âœ“ Soporta multi-GPU con accelerate
- âœ“ Logging con WandB/TensorBoard
- âœ“ Guardado de checkpoints
- âœ“ EvaluaciÃ³n automÃ¡tica

**Uso**:
```bash
accelerate launch scripts/train_catalan.py \
    --config configs/config_catalan.yaml
```

### 2. ConfiguraciÃ³n

#### `configs/config_catalan.yaml`
Archivo central de configuraciÃ³n:
```yaml
# Dataset
TTS_dataset: "./data/tokenized"  # O tu dataset en HF

# Modelo
model_name: "canopylabs/orpheus-tts-0.1-pretrained"

# Entrenamiento
training:
  epochs: 3
  batch_size: 2
  learning_rate: 5.0e-5
  bf16: true

# Voces por dialecto
data:
  voice_mapping:
    central: "pau"
    balearic: "maria"
    valencian: "carla"
```

### 3. Setup AutomÃ¡tico

#### `setup_runpod.sh`
Script bash que configura TODO el entorno en RunPod:
- âœ“ Instala PyTorch con CUDA
- âœ“ Instala todas las dependencias
- âœ“ Configura estructura de directorios
- âœ“ Crea variables de entorno
- âœ“ Genera scripts auxiliares
- âœ“ Configura Jupyter notebooks

**Uso**:
```bash
chmod +x setup_runpod.sh
./setup_runpod.sh
```

## Pipeline Completo

### Fase 1: Setup (1 vez)
```bash
# En RunPod
./setup_runpod.sh

# AutenticaciÃ³n
huggingface-cli login
wandb login
```

### Fase 2: PreparaciÃ³n de Datos
```bash
# Procesar tus datasets
python scripts/prepare_custom_catalan.py \
    --datasets xaviviro/cv_23_ca_central \
    --output_dir ./data/processed \
    --samples_per_variant 500

# Resultado: ~1,500 muestras procesadas y balanceadas
```

### Fase 3: TokenizaciÃ³n
```bash
# Tokenizar audio + texto
python scripts/tokenize_dataset.py \
    --input_dir ./data/processed \
    --output_dir ./data/tokenized \
    --device cuda

# Resultado: Dataset listo para entrenamiento
```

### Fase 4: Entrenamiento
```bash
# Configurar
nano configs/config_catalan.yaml

# Entrenar
accelerate launch scripts/train_catalan.py \
    --config configs/config_catalan.yaml

# Resultado: Modelo fine-tuneado en ./checkpoints/
```

## AnÃ¡lisis de los Datasets

### Â¿Por quÃ© necesitan tratamiento?

Los datasets de Common Voice **requieren preprocesamiento significativo**:

1. **Frecuencia de muestreo**: 48kHz â†’ 24kHz (requerido por Orpheus)
2. **DuraciÃ³n**: Filtrar audios muy cortos (<1s) o muy largos (>30s)
3. **Calidad**: Filtrar por votos, calidad anotada
4. **Formato**: Convertir texto a formato `{voz}: {texto}`
5. **Balanceo**: Equilibrar muestras entre dialectos
6. **TokenizaciÃ³n**: Convertir audio a tokens discretos con SNAC

### Tratamiento Implementado

| Problema | SoluciÃ³n |
|----------|----------|
| Audio en 48kHz | Resampleo a 24kHz con librosa |
| Audios muy cortos/largos | Filtros de duraciÃ³n configurables |
| Calidad variable | Filtros de metadatos (votos, gÃ©nero, edad) |
| Formato de texto | Preprocesamiento con prefijo de voz |
| Desbalanceo dialectal | Sampling estratificado por variante |
| TokenizaciÃ³n de audio | SNAC con 3 niveles jerÃ¡rquicos |

### Proceso de TokenizaciÃ³n

```
Texto: "pau: Bon dia!"
  â†“
Tokenizer de Texto (Llama)
  â†“
[128000, 79, 2933, 25, 13789, 47387, 0]  (7 tokens)

Audio: 5 segundos a 24kHz
  â†“
SNAC Encoder (3 niveles)
  â†“
Nivel 1 (coarse):  375 tokens  (75 Hz)
Nivel 2 (medium):  750 tokens  (150 Hz)
Nivel 3 (fine):    1,500 tokens (300 Hz)

Total: ~2,625 tokens

Secuencia Final:
[text_tokens] + [audio_tokens_l1] + [audio_tokens_l2] + [audio_tokens_l3]
= 7 + 2,625 = 2,632 tokens
```

## Recursos Necesarios

### Hardware MÃ­nimo (para probar)
- GPU: RTX 3090 / 4090 (24GB VRAM)
- RAM: 32GB
- Disco: 100GB
- Tiempo: ~4 horas para 500 samples

### Hardware Recomendado (para producciÃ³n)
- GPU: A100 40GB o H100
- RAM: 64GB
- Disco: 500GB
- Tiempo: ~6 horas para 2,000 samples

### Uso de Recursos

| Fase | VRAM | RAM | Tiempo (500 samples) |
|------|------|-----|---------------------|
| PreparaciÃ³n | - | 4GB | 5-10 min |
| TokenizaciÃ³n | 4GB | 8GB | 30-60 min |
| Entrenamiento | 16GB | 16GB | 2-4 horas |

## GuÃ­as de DocumentaciÃ³n

1. **[QUICKSTART.md](QUICKSTART.md)** â†’ Empieza aquÃ­ para empezar rÃ¡pido
2. **[README.md](README.md)** â†’ DocumentaciÃ³n completa
3. **[USAGE_CUSTOM_DATASETS.md](USAGE_CUSTOM_DATASETS.md)** â†’ Para tus datasets especÃ­ficos
4. **[TOKENIZATION_GUIDE.md](TOKENIZATION_GUIDE.md)** â†’ Entender la tokenizaciÃ³n

## PrÃ³ximos Pasos

1. **Probar con dataset pequeÃ±o**: 100 samples para validar pipeline
2. **Escalar**: Aumentar a 500-1000 samples por dialecto
3. **Evaluar**: Revisar mÃ©tricas y calidad de audio
4. **Iterar**: Ajustar hiperparÃ¡metros segÃºn resultados
5. **ProducciÃ³n**: Entrenar modelo final con todos los datos

## Soporte para Variantes Dialectales

El sistema soporta:

| Dialecto | Dataset | Voz | Ejemplo |
|----------|---------|-----|---------|
| Central | `xaviviro/cv_23_ca_central` | pau | `pau: Bon dia!` |
| Balear | `xaviviro/cv_23_ca_balearic` | maria | `maria: Bon dia!` |
| ValenciÃ  | `xaviviro/cv_23_ca_valencian` | carla | `carla: Bon dia!` |
| Nord | `xaviviro/cv_23_ca_northern` | montse | `montse: Bon dia!` |
| Nord-occidental | `xaviviro/cv_23_ca_northwestern` | jordi | `jordi: Bon dia!` |

## CaracterÃ­sticas Principales

âœ… **Soporte multi-dialectal** con voces diferenciadas
âœ… **Pipeline completo** de datos a modelo entrenado
âœ… **Setup automÃ¡tico** para RunPod
âœ… **Filtros configurables** de calidad y metadatos
âœ… **TokenizaciÃ³n jerÃ¡rquica** con SNAC
âœ… **Entrenamiento optimizado** con bf16 y gradient checkpointing
âœ… **Logging completo** con WandB/TensorBoard
âœ… **DocumentaciÃ³n extensa** con ejemplos

## Comandos RÃ¡pidos

```bash
# Setup completo
./setup_runpod.sh

# Pipeline bÃ¡sico
python scripts/prepare_custom_catalan.py --datasets xaviviro/cv_23_ca_central --output_dir ./data/processed
python scripts/tokenize_dataset.py --input_dir ./data/processed --output_dir ./data/tokenized
accelerate launch scripts/train_catalan.py --config configs/config_catalan.yaml

# Monitoreo
watch -n 1 nvidia-smi
tensorboard --logdir ./logs/
```

## Contacto

Para problemas o preguntas:
- Repositorio Orpheus: https://github.com/canopyai/Orpheus-TTS
- DocumentaciÃ³n Orpheus: https://canopylabs.ai/

---

**Creado**: 2025-11-06
**VersiÃ³n**: 1.0
**Para**: Fine-tuning de Orpheus TTS en CatalÃ¡n con variantes dialectales
